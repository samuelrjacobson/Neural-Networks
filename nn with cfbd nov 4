import numpy as np
import pandas as pd
from cfbd import Configuration, ApiClient, TeamsApi, GamesApi, StatsApi
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error

# Securely load the API key
configuration = Configuration()
configuration.api_key['Authorization'] = 'PIX1Z54E93iZiIa+ZPDwFxhiI+pcS+ZsOjQYcPwIUI9dWJDf5/ur3C+X21aXgKVq'
configuration.api_key_prefix['Authorization'] = 'Bearer'

api_client = ApiClient(configuration)
teams_api = TeamsApi(api_client)
games_api = GamesApi(api_client)
stats_api = StatsApi(api_client)


# Teams and years of interest
teams = ["Michigan", "Michigan State", "Ohio State", "Penn State", "Maryland", "Indiana", "Rutgers"]
years = [2024, 2023, 2022, 2021, 2020, 2019]

# Fetch seasonal statistics for each team
# Fetch seasonal statistics for each team
team_season_stats_list = []
for year in years:
    for team in teams:
        try:
            team_season_stats = stats_api.get_team_season_stats(year=year, team=team)

            # Create a dictionary to hold the stats for easy access
            stats_dict = {}
            for stat in team_season_stats:
                stats_dict[stat.stat_name] = stat.stat_value
            
            # Extract necessary stats with defaults if not present
            passAttempts = stats_dict.get('passAttempts', 0)
            passCompletions = stats_dict.get('passCompletions', 0)

            passCompPercent = (
                0 if passAttempts == 0 else passCompletions / passAttempts
            )

            season_stats_dict = {
                'team': team,
                'year': year,
                'passCompPercent': passCompPercent,
                'passingTDs': stats_dict.get('passingTDs', 0),
                'rushingTDs': stats_dict.get('rushingTDs', 0),
                'penaltyYards': stats_dict.get('penaltyYards', 0),
                'fumblesLost': stats_dict.get('fumblesLost', 0),
                'interceptions': stats_dict.get('interceptions', 0),
                'fumblesRecovered': stats_dict.get('fumblesRecovered', 0),
                'passesIntercepted': stats_dict.get('passesIntercepted', 0)
            }

            team_season_stats_list.append(season_stats_dict)
        
        except Exception as e:
            print(f"Error fetching season stats for {team} in {year}: {e}")

# Convert seasonal stats to DataFrame
df_season_stats = pd.DataFrame(team_season_stats_list)


# Fetch game-specific data
team_game_stats_list = []
for year in years:
    for team in teams:
        try:
            response = games_api.get_games(year=year, team=team, season_type='regular')
            games = response

            for game in games:
                # Skip games that haven't been played yet
                if game.home_points is None or game.away_points is None:
                    continue

                if game.home_team == team:
                    opponent = game.away_team
                    points_for = game.home_points
                    points_against = game.away_points
                else:
                    opponent = game.home_team
                    points_for = game.away_points
                    points_against = game.home_points

                game_stats_dict = {
                    'team': team,
                    'opponent': opponent,
                    'points_for': points_for,
                    'points_against': points_against,
                    'year': year,
                    'week': game.week
                }
                team_game_stats_list.append(game_stats_dict)
        except Exception as e:
            print(f"Error fetching data for {team} in {year}: {e}")

# Convert game-specific data to DataFrame
df_game_stats = pd.DataFrame(team_game_stats_list)

# Merge game data with seasonal stats
df_combined = df_game_stats.merge(df_season_stats, on=['team', 'year'], how='left')

# Preprocess data
df_combined.fillna(0, inplace=True)

# Define target variables
targets = df_combined[['points_for', 'points_against']]

# Define feature columns
feature_columns = [
    'team', 'opponent', 'year', 'week', 'passCompPercent', 'passingTDs', 'rushingTDs',
    'penaltyYards', 'fumblesLost', 'interceptions', 'fumblesRecovered', 'passesIntercepted'
]
features = df_combined[feature_columns]

# Retain 'team' and 'opponent' names for output
team_opponent = df_combined[['team', 'opponent']]

# One-hot encode categorical features
features_encoded = pd.get_dummies(features, columns=['team', 'opponent'], drop_first=True)

# Standardize features
scaler_features = StandardScaler()
standardized_features = scaler_features.fit_transform(features_encoded)

# Scale target variables from 0 to 1
scaler_targets = MinMaxScaler()
scaled_targets = scaler_targets.fit_transform(targets)

# Split data into training and testing sets
X_train, X_test, y_train, y_test, team_train, team_test = train_test_split(
    standardized_features, scaled_targets, team_opponent, test_size=0.2, random_state=42
)

# Initialize neural network weights and biases
def xavier_init(size_in, size_out):
    limit = np.sqrt(6 / (size_in + size_out))
    return np.random.uniform(-limit, limit, (size_in, size_out))

input_neurons = X_train.shape[1]
hidden_neurons_1 = 10
hidden_neurons_2 = 5
output_neurons = 2
learning_rate = 0.01
epochs = 10000

np.random.seed(0)
weights_input_hidden1 = xavier_init(input_neurons, hidden_neurons_1)
weights_hidden1_hidden2 = xavier_init(hidden_neurons_1, hidden_neurons_2)
weights_hidden2_output = xavier_init(hidden_neurons_2, output_neurons)

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# Training loop
for epoch in range(epochs):
    hidden_layer1_input = np.dot(X_train, weights_input_hidden1)
    hidden_layer1_output = sigmoid(hidden_layer1_input)

    hidden_layer2_input = np.dot(hidden_layer1_output, weights_hidden1_hidden2)
    hidden_layer2_output = sigmoid(hidden_layer2_input)

    predicted_output = np.dot(hidden_layer2_output, weights_hidden2_output)

    error = np.mean((y_train - predicted_output) ** 2)

    output_error = y_train - predicted_output
    output_delta = output_error

    hidden_layer2_error = np.dot(output_delta, weights_hidden2_output.T)
    hidden_layer2_delta = hidden_layer2_error * sigmoid_derivative(hidden_layer2_output)

    hidden_layer1_error = np.dot(hidden_layer2_delta, weights_hidden1_hidden2.T)
    hidden_layer1_delta = hidden_layer1_error * sigmoid_derivative(hidden_layer1_output)

    weights_hidden2_output += np.dot(hidden_layer2_output.T, output_delta) * learning_rate
    weights_hidden1_hidden2 += np.dot(hidden_layer1_output.T, hidden_layer2_delta) * learning_rate
    weights_input_hidden1 += np.dot(X_train.T, hidden_layer1_delta) * learning_rate

    if epoch % 1000 == 0:
        print(f"Epoch {epoch}, Error: {error}")

# Testing
hidden_layer1_input = np.dot(X_test, weights_input_hidden1)
hidden_layer1_output = sigmoid(hidden_layer1_input)

hidden_layer2_input = np.dot(hidden_layer1_output, weights_hidden1_hidden2)
hidden_layer2_output = sigmoid(hidden_layer2_input)

predicted_output = np.dot(hidden_layer2_output, weights_hidden2_output)

predicted_output_unscaled = scaler_targets.inverse_transform(predicted_output)
y_test_unscaled = scaler_targets.inverse_transform(y_test)

test_error = mean_squared_error(y_test_unscaled, predicted_output_unscaled)
print(f"\nTest MSE: {test_error}\n")

print("Predictions vs Actual:")
print("Team vs Opponent | Team Predicted | Opponent Predicted | Team Actual | Opponent Actual")
print("-" * 80)
for i in range(min(len(y_test_unscaled), 10)):
    team = team_test.iloc[i]['team']
    opponent = team_test.iloc[i]['opponent']
    pred_for = predicted_output_unscaled[i][0]
    pred_against = predicted_output_unscaled[i][1]
    actual_for = y_test_unscaled[i][0]
    actual_against = y_test_unscaled[i][1]
    print(f"{team} vs {opponent} | {pred_for:.2f} | {pred_against:.2f} | {actual_for} | {actual_against}")
